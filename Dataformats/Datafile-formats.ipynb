{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File formats\n",
    "\n",
    "### numpy, matlab etc binary: **.npy, .npz or .mat**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data['text'] = 'Something'\n",
    "data['array'] = np.zeros((10,10))\n",
    "\n",
    "np.savez('data.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical Data Format (**HDF5**) - https://www.hdfgroup.org/solutions/hdf5/\n",
    "\n",
    "Because it uses B-trees to index table objects, HDF5 works well for time series data such as stock price series, network monitoring data, or 3D meteorological data. The bulk of the data goes into straightforward arrays (the table objects) that can be accessed much more quickly than the rows of an SQL database, but B-tree access is available for non-array data too. The HDF5 data storage mechanism can be simpler and faster than an SQL star schema.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation: https://portal.hdfgroup.org/display/HDF5/Introduction+to+HDF5\n",
    "\n",
    "* Simulations and numerical calculations (or gathered data) -> lot of data\n",
    "* Scanning through it takes up time\n",
    "* HDD blocks and sectors\n",
    "* Storing large data efficiently\n",
    "* B-tree search "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "About B-trees:\n",
    "https://www.youtube.com/watch?v=aZjYr87r1b8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Disadvantages:\n",
    "  * Can't use grep, awk ... \n",
    "  * deleting slices won't make its size smaller\n",
    "  * corrupt data corrupts the whole file\n",
    "\n",
    "* [trillion particle plasma physics simulation](https://www.hdfgroup.org/trillion-particle/), which needed to store HDF5 files of 40 terabytes or more, and had to be able to sustainably write data at rates exceeding 50 gigabytes per second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.random((400, 400, 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 400, 400)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('test.hdf', 'w') as outfile:\n",
    "    dset = outfile.create_dataset('random_dataset', data=data, chunks=True)\n",
    "    dset.attrs['some key'] = 'Did you want some metadata?'\n",
    "    dset.attrs['rand_type'] = 'random'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# This examaple creates an HDF5 file dset.h5 and an empty datasets /dset in it.\n",
    "#\n",
    "import h5py\n",
    "#\n",
    "# Create a new file using defaut properties.\n",
    "#\n",
    "file = h5py.File('dset.h5','w')\n",
    "#\n",
    "# Create a dataset under the Root group.\n",
    "#\n",
    "dataset = file.create_dataset(\"dset\",(4, 6), h5py.h5t.STD_I32BE)\n",
    "print \"Dataset dataspace is\", dataset.shape\n",
    "print \"Dataset Numpy datatype is\", dataset.dtype\n",
    "print \"Dataset name is\", dataset.name\n",
    "print \"Dataset is a member of the group\", dataset.parent\n",
    "print \"Dataset was created in the file\", dataset.file\n",
    "#\n",
    "# Close the file before exiting\n",
    "#\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Network Common Data Form (**netcdf**) - https://www.unidata.ucar.edu/software/netcdf/docs/netcdf_introduction.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# This examaple creates an HDF5 file dset.h5 and an empty datasets /dset in it.\n",
    "#\n",
    "import h5py\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset dataspace is (4, 6)\n",
      "Dataset Numpy datatype is >i4\n",
      "Dataset name is /dset\n",
      "Dataset is a member of the group <HDF5 group \"/\" (1 members)>\n",
      "Dataset was created in the file <HDF5 file \"dset.h5\" (mode r+)>\n"
     ]
    }
   ],
   "source": [
    "# Create a new file using defaut properties.\n",
    "#\n",
    "file = h5py.File('dset.h5','w')\n",
    "#\n",
    "# Create a dataset under the Root group.\n",
    "#\n",
    "dataset = file.create_dataset(\"dset\",(4, 6), h5py.h5t.STD_I32BE)\n",
    "print (\"Dataset dataspace is\", dataset.shape)\n",
    "print( \"Dataset Numpy datatype is\", dataset.dtype)\n",
    "print (\"Dataset name is\", dataset.name)\n",
    "print( \"Dataset is a member of the group\", dataset.parent)\n",
    "print( \"Dataset was created in the file\", dataset.file)\n",
    "#\n",
    "# Close the file before exiting\n",
    "#\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# This example writes data to the existing empty dataset created by h5_crtdat.py and then reads it back.\n",
    "#\n",
    "import h5py\n",
    "import numpy as np\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4  5  6]\n",
      " [ 7  8  9 10 11 12]\n",
      " [13 14 15 16 17 18]\n",
      " [19 20 21 22 23 24]]\n",
      "Writing data...\n",
      "Reading data back...\n",
      "Printing data...\n",
      "[[ 1  2  3  4  5  6]\n",
      " [ 7  8  9 10 11 12]\n",
      " [13 14 15 16 17 18]\n",
      " [19 20 21 22 23 24]]\n"
     ]
    }
   ],
   "source": [
    "# Open an existing file using default properties.\n",
    "#\n",
    "file = h5py.File('dset.h5','r+')\n",
    "#\n",
    "# Open \"dset\" dataset under the root group.\n",
    "#\n",
    "dataset = file['/dset']\n",
    "print(dataset[:])\n",
    "#\n",
    "# Initialize data object with 0.\n",
    "#\n",
    "data = np.zeros((4,6))\n",
    "#\n",
    "# Assign new values\n",
    "#\n",
    "for i in range(4):\n",
    "    for j in range(6):\n",
    "        data[i][j]= i*6+j+1\t \n",
    "#\n",
    "# Write data\n",
    "#\n",
    "print(\"Writing data...\")\n",
    "dataset[...] = data\n",
    "#\n",
    "# Read data back and print it.\n",
    "#\n",
    "print(\"Reading data back...\")\n",
    "data_read = dataset[...]\n",
    "print(\"Printing data...\")\n",
    "print (data_read)\n",
    "#\n",
    "# Close the file before exiting\n",
    "#\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f['data'].dims[0].label = 'z'\n",
    "f['data'].dims[2].label = 'x'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating HDF5 file group.h5...\n",
      "Creating group MyGroup in the file...\n",
      "Creating group Group_A in MyGroup using absolute path...\n",
      "Creating group Group_B in MyGroup using relative path...\n",
      "Printing members of MyGroup group: <KeysViewHDF5 ['Group_A', 'Group_B']>\n"
     ]
    }
   ],
   "source": [
    "# Absolute and relative paths are used to create groups in MyGroup. \n",
    "#\n",
    "import sys\n",
    "import h5py\n",
    "\n",
    "#\n",
    "# Use 'w' to remove existing file and create a new one; use 'w-' if\n",
    "# create operation should fail when the file already exists.\n",
    "#\n",
    "print( \"Creating HDF5 file group.h5...\")\n",
    "file = h5py.File('group.h5','w')\n",
    "#\n",
    "# Create a group with the name \"MyGroup\"\n",
    "#\n",
    "print (\"Creating group MyGroup in the file...\")\n",
    "group = file.create_group(\"MyGroup\")\n",
    "#\n",
    "# Create group \"Group_A\" in group MyGroup\n",
    "#\n",
    "print( \"Creating group Group_A in MyGroup using absolute path...\")\n",
    "group_a = file.create_group(\"/MyGroup/Group_A\")\n",
    "#\n",
    "# Create group \"Group_B\" in group MyGroup\n",
    "#\n",
    "print( \"Creating group Group_B in MyGroup using relative path...\")\n",
    "group_b = group.create_group(\"Group_B\")\n",
    "# \n",
    "# Print the contents of MyGroup group\n",
    "#\n",
    "print (\"Printing members of MyGroup group:\", group.keys())\n",
    "#\n",
    "# Close the file before exiting; H5Py will close the groups we created.\n",
    "#\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
